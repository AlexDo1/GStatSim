{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook GlacierStats.ipynb to script\n",
      "[NbConvertApp] Writing 5327 bytes to GlacierStats.py\n"
     ]
    }
   ],
   "source": [
    "### geostatistical tools\n",
    "!jupyter nbconvert --to script GlacierStats.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "from sklearn.neighbors import KDTree\n",
    "import math\n",
    "from scipy.spatial import distance_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance function definition\n",
    "def covar(t, d, r):\n",
    "    h = d / r\n",
    "    if t == 1:  # Spherical\n",
    "        c = 1 - h * (1.5 - 0.5 * np.square(h))\n",
    "        c[h > 1] = 0\n",
    "    elif t == 2:  # Exponential\n",
    "        c = np.exp(-3 * h)\n",
    "    elif t == 3:  # Gaussian\n",
    "        c = np.exp(-3 * np.square(h))\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "# get variogram along the major or minor axis\n",
    "def axis_var(lagh, nug, nstruct, cc, vtype, a):\n",
    "    lagh = lagh\n",
    "    nstruct = nstruct # number of variogram structures\n",
    "    vtype = vtype # variogram types (Gaussian, etc.)\n",
    "    a = a # range for axis in question\n",
    "    cc = cc # contribution of each structure\n",
    "    \n",
    "    n = len(lagh)\n",
    "    gamma_model = np.zeros(shape = (n))\n",
    "    \n",
    "    # for each lag distance\n",
    "    for j in range(0,n):\n",
    "        c = nug\n",
    "        c = 0\n",
    "        h = np.matrix(lagh[j])\n",
    "        \n",
    "        # for each structure in the variogram\n",
    "        for i in range(nstruct):\n",
    "            Q = h.copy()\n",
    "            d = Q / a[i]\n",
    "            c = c + covar(vtype[i], d, 1) * cc[i] # covariance\n",
    "        \n",
    "        gamma_model[j] = 1+ nug - c # variance\n",
    "    return gamma_model\n",
    "\n",
    "\n",
    "\n",
    "# make array of x,y coordinates based on corners and resolution\n",
    "def pred_grid(xmin, xmax, ymin, ymax, pix):\n",
    "    cols = (xmax - xmin)/pix; rows = (ymax - ymin)/pix  # number of rows and columns\n",
    "    x = np.arange(xmin,xmax,pix); y = np.arange(ymin,ymax,pix) # make arrays\n",
    "\n",
    "    xx, yy = np.meshgrid(x,y) # make grid\n",
    "    yy = np.flip(yy) # flip upside down\n",
    "\n",
    "    # shape into array\n",
    "    x = np.reshape(xx, (int(rows)*int(cols), 1))\n",
    "    y = np.reshape(yy, (int(rows)*int(cols), 1))\n",
    "\n",
    "    Pred_grid_xy = np.concatenate((x,y), axis = 1) # combine coordinates\n",
    "    return Pred_grid_xy\n",
    "\n",
    "\n",
    "\n",
    "# rotation matrix (Azimuth = major axis direction)\n",
    "def Rot_Mat(Azimuth, a_max, a_min):\n",
    "    theta = (Azimuth / 180.0) * np.pi\n",
    "    Rot_Mat = np.dot(\n",
    "        np.array([[1 / a_max, 0], [0, 1 / a_min]]),\n",
    "        np.array(\n",
    "            [\n",
    "                [np.cos(theta), np.sin(theta)],\n",
    "                [-np.sin(theta), np.cos(theta)],\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    return Rot_Mat\n",
    "\n",
    "\n",
    "\n",
    "# covariance model\n",
    "def cov(h1, h2, k, vario):\n",
    "    # unpack variogram parameters\n",
    "    Azimuth = vario[0]\n",
    "    nug = vario[1]\n",
    "    nstruct = vario[2]\n",
    "    vtype = vario[3]\n",
    "    cc = vario[4]\n",
    "    a_max = vario[5]\n",
    "    a_min = vario[6]\n",
    "    \n",
    "    c = -nug # nugget effect is made negative because we're calculating covariance instead of variance\n",
    "    for i in range(nstruct):\n",
    "        Q1 = h1.copy()\n",
    "        Q2 = h2.copy()\n",
    "        \n",
    "        # covariances between measurements\n",
    "        if k == 0:\n",
    "            d = distance_matrix(\n",
    "                np.matmul(Q1, Rot_Mat(Azimuth, a_max[i], a_min[i])),\n",
    "                np.matmul(Q2, Rot_Mat(Azimuth, a_max[i], a_min[i])),\n",
    "            )\n",
    "            \n",
    "        # covariances between measurements and unknown\n",
    "        elif k == 1:\n",
    "            d = np.sqrt(\n",
    "                np.square(\n",
    "                    (np.matmul(Q1, Rot_Mat(Azimuth, a_max[i], a_min[i])))\n",
    "                    - np.tile(\n",
    "                        (\n",
    "                            np.matmul(\n",
    "                                Q2, Rot_Mat(Azimuth, a_max[i], a_min[i])\n",
    "                            )\n",
    "                        ),\n",
    "                        (k, 1),\n",
    "                    )\n",
    "                ).sum(axis=1)\n",
    "            )\n",
    "            d = np.asarray(d).reshape(len(d))\n",
    "        c = c + covar(vtype[i], d, 1) * cc[i]\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "# simple kriging\n",
    "def krige(Pred_grid, df, xx, yy, data, k, vario):\n",
    "    \n",
    "    Mean_1 = np.average(df[data]) # mean of data\n",
    "    Var_1 = np.var(df[data]); # variance of data \n",
    "    \n",
    "    # make KDTree to search data for nearest neighbors\n",
    "    tree_data = KDTree(df[[xx,yy]].values) \n",
    "    \n",
    "    # preallocate space for mean and variance\n",
    "    est_SK = np.zeros(shape=len(Pred_grid))\n",
    "    var_SK = np.zeros(shape=len(Pred_grid))\n",
    "    \n",
    "    X_Y = np.zeros((1, k, 2))\n",
    "    closematrix_Primary = np.zeros((1, k))\n",
    "    neardistmatrix = np.zeros((1, k))\n",
    "    \n",
    "    for z in tqdm(range(0, len(Pred_grid))):\n",
    "        # find nearest data points\n",
    "        nearest_dist, nearest_ind = tree_data.query(Pred_grid[z : z + 1, :], k=k)\n",
    "        a = nearest_ind.ravel()\n",
    "        group = df.iloc[a, :]\n",
    "        closematrix_Primary[:] = group[data]\n",
    "        neardistmatrix[:] = nearest_dist\n",
    "        X_Y[:, :] = group[[xx, yy]]\n",
    "        \n",
    "        # left hand side (covariance between data)\n",
    "        Kriging_Matrix = np.zeros(shape=((k, k)))\n",
    "        Kriging_Matrix = cov(X_Y[0], X_Y[0], 0, vario)\n",
    "        \n",
    "        # Set up Right Hand Side (covariance between data and unknown)\n",
    "        r = np.zeros(shape=(k))\n",
    "        k_weights = r\n",
    "        r = cov(X_Y[0], np.tile(Pred_grid[z], (k, 1)), 1, vario)\n",
    "        Kriging_Matrix.reshape(((k)), ((k)))\n",
    "        \n",
    "        # Calculate Kriging Weights\n",
    "        k_weights = np.dot(np.linalg.pinv(Kriging_Matrix), r)\n",
    "\n",
    "        # get estimates\n",
    "        est_SK[z] = k*Mean_1 + np.sum(k_weights*(closematrix_Primary[:] - Mean_1))\n",
    "        var_SK[z] = Var_1 - np.sum(k_weights*r)\n",
    "        \n",
    "    return est_SK, var_SK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
